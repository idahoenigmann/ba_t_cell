\chapter{Approximating the Calcium Concentration}
\label{chapter:approximating}

If we have a look at the typical trajectory of the calcium concentration in activated and unactivated cells, shown in figure~\ref{fig:all_cells_overlayed}, we can see differences emerging. For one the maximum concentration value reached by most activated cells is higher. Another distinguishing feature is the presence of a steep incline at the moment of activation.

\begin{figure}[h]
	\centering
	\begin{subfigure}{0.45\linewidth}
		\includegraphics[width=\textwidth]{fig/all_cells_overlayed_mouse_neg}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\linewidth}
		\includegraphics[width=\textwidth]{fig/all_cells_overlayed_mouse_pos}
	\end{subfigure}
	
	\caption{Two plots of the overlapping calcium concentration time series of cells. On the left a negative control and on the right a positive control of mouse cells.}
	\label{fig:all_cells_overlayed}
\end{figure}

By modelling the time series with a function incorporating features such as the increase, maximum value and oscillations present in the decrease afterwards, we can extract these features more easily. By doing this, using approximation methods from chapter~\ref{chapter:optimization}, we hope to have an easier method to answer the questions from the introduction.

\section{Approximation Function}

From studying the data in the two control groups we find to expect a function close to
\begin{align}
	\label{math:function_unactivated_cell}
	f_{unac}(x) := u
\end{align}
for unactivated cells and
\begin{align}
	\label{math:function_activated_cell}
	f_{ac}(x) := \begin{cases}
		\frac{a-u}{1 + e^{-k_1(x-w_1)}} + u & \textbf{ if } x <= t\\
		\frac{a-d}{1 + e^{-k_2(x-w_2)}} + d & \textbf{ else}
	\end{cases}
\end{align}
for activated cells. The parameters can be understood as described in table~\ref{tab:parameters}.

\begin{table}[h!]
	\centering
	\begin{tabular}{|cl|}
		\hline
		$u$ ... & average value before activation, \\
		\hline
		$a$ ... & value reached at the peak of activation, \\
		\hline
		$d$ ... & average value after activation, \\
		\hline
		$k_1$ ... & steepness of increase, \\
		\hline
		$k_2$ ... & steepness of decrease, \\
		\hline
		$w_1$ ... & time point at which the increase happens, \\
		\hline
		$w_2$ ... & time point at which the decrease happens, \\
		\hline
		$t$ ... & time point at which the increase ends, and the decrease starts, \\
		\hline
	\end{tabular}
	\caption{List of parameters and their interpretation.}
	\label{tab:parameters}
\end{table}

Figure~\ref{fig:typical_time_series_with_parameters} shows the above functions~\ref{math:function_unactivated_cell} and~\ref{math:function_activated_cell}, and shows the relations to the parameters in unactivated and activated cells. The similarity between these functions and figure~\ref{fig:all_cells_overlayed} can be observed.

% start = 50, u = 0.9, a = 4, k1 = 0.075, k2 = -0.04, w1 = 300, w2 = 520, t = 400, d = 2, z = 800

\begin{figure}[h]
	\centering
	\begin{subfigure}{0.45\linewidth}
	  \begin{tikzpicture}
		\datavisualization [scientific axes, visualize as line,
			x axis = {
				min value = 0,
				max value = 1000,
				length = 5cm,
				ticks and grid = {major={at={0 as $t$}}, color=white},
				label = frame
			},
			y axis = {
				min value = 0,
				max value = 5,
				length = 5cm,
				ticks and grid = {major={at={0.9 as $u$}}},
				label = ratio
			},
		]
		data [format=function] {
			var x : interval [50:800]; func y = 0.9;
		};
	\end{tikzpicture}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\linewidth}
		\begin{tikzpicture}
			\datavisualization [scientific axes, visualize as line,
			x axis = {
				min value = 0,
				max value = 1000,
				length = 5cm,
				ticks and grid = {major={at={300 as $w_1$, 400 as $t$, 520 as $w_2$}}},
				label = frame
			}, y axis = {
				min value = 0,
				max value = 5,
				length = 5cm,
				ticks and grid = {major={at={0.9 as $u$, 2 as $d$, 4 as $a$}}},
				label = ratio
			},
			]
			data [separator=\space] {
				x y
				50 0.9000000223018123
				60 0.9000000472129365
				70 0.9000000999497857
				80 0.9000002115936903
				90 0.9000004479438116
				100 0.9000009482969035
				110 0.9000020075438745
				120 0.9000042499673413
				130 0.9000089971671542
				140 0.9000190469412669
				150 0.9000403220982461
				160 0.9000853606424553
				170 0.9001807029235496
				180 0.9003825231855573
				190 0.9008096899891967
				200 0.9017136137744631
				210 0.9036254818216721
				220 0.9076651317855678
				230 0.9161823896500311
				240 0.9340595221548389
				250 0.9712298467210794
				260 1.047020206850457
				270 1.1955833411872394
				280 1.4655191237997047
				290 1.8945460325562817
				300 2.45
				310 3.005453967443718
				320 3.434480876200295
				330 3.704416658812761
				340 3.8529797931495433
				350 3.9287701532789203
				360 3.9659404778451615
				370 3.983817610349969
				380 3.9923348682144324
				390 3.9963745181783277
				400 3.998286386225537
				410 3.9757431300314514
				420 3.964027580075817
				430 3.946806012846268
				440 3.9216685544064713
				450 3.8853516482022625
				460 3.8336546070121553
				470 3.7615941559557644
				480 3.664036770267849
				490 3.537049566998035
				500 3.379948962255225
				510 3.197375320224904
				520 3.0
				530 2.802624679775096
				540 2.620051037744775
				550 2.4629504330019647
				560 2.335963229732151
				570 2.238405844044235
				580 2.1663453929878447
				590 2.1146483517977375
				600 2.0783314455935287
				610 2.053193987153732
				620 2.035972419924183
				630 2.0242568699685486
				640 2.0163251423063198
				650 2.010972597798901
				660 2.007368479798872
				670 2.0049452463132695
				680 2.0033176021603487
				690 2.0022250720657206
				700 2.0014920576676736
				710 2.001000402214159
				720 2.0006707002609327
				730 2.0004496335404665
				740 2.0003014207161196
				750 2.0002020583878157
				760 2.0001354482992397
				770 2.000090795737405
				780 2.0000608631138013
				790 2.00004079817456
			}
			info {
			\draw (visualization cs: x=300, y=2.5)
			node [left,font=\footnotesize] {$k_1$};
			\draw (visualization cs: x=520, y=3.1)
			node [right,font=\footnotesize] {$k_2$};
			};
		\end{tikzpicture}
	\end{subfigure}
	
	\caption{Left shows the function $f_{unac}$ defined in~\ref{math:function_unactivated_cell} with the parameter $u$. The right shows the function $f_{ac}$ defined in~\ref{math:function_activated_cell} with the parameters $u$, $d$, $a$, $w_1$, $t$, $w_2$, $k_1$ and $k_2$.}
	\label{fig:typical_time_series_with_parameters}
\end{figure}

For our model to make sense we have to impose some conditions onto the parameters. We expect

\begin{align*}
	0 \leq u \leq d \leq a, && w_1 \leq t \leq w_2, && k_1 > 0 && \text{and} && k_2 < 0.
\end{align*}

There are multiple ways in which the parameters of $f_{ac}$ can be chosen to get a function similar to $f_{unac}$. If $w_1$ is very large or $u \approx d \approx a$ then $f_{ac}$ approaches a constant value of $u$, thus approximating $f_{unac}$. If the approximation of a cell has parameters with $w_1$ very large or $u \approx d \approx a$ we can therefore expect it to be of an unactivated cell. Otherwise, it is more probable to be activated.

\section{Implementation of the Approximation}

Now that we have defined our model functions we will implement a routine that fits such a $f_{ac}$-function through the data points of a particle recording.

First we give the pseudocode for approximating a single particles time series with the approximation function described above. It takes a (frame, ratio)-matrix of a single particle as input and returns the corresponding parameter list of the approximation.

\begin{algorithm}[H] \label{alg:approximate}
	\SetAlgoLined
	\DontPrintSemicolon
	\LinesNumbered
	\SetKwInOut{Input}{input}
	\SetKwInOut{Output}{output}
	\caption{Approximate}
	
	\Input{particle data as (frame, ratio) matrix}
	\Output{parameters describing the approximation}
	
	\BlankLine
	\Begin{
		set boundaries for parameters\;
		set start values for parameters\;
		use Trust Region Reflective Algorithm with boundaries and start values to get parameters\;
		calculate corresponding approximation and add as fit\_sigmoid columns to data matrix\;
		\Return{parameters}\;
	}
\end{algorithm}
\vspace{1cm}

The parameters of $f_{ac}$ used in the approximation are not independent of each other as we want to choose $t$ to be the point at which the increasing part of the function, $(a-u)/(1+e^{-k_1(x-w_1)})$, almost reaches the value $a$. We choose

\begin{align*}
	t := w_1 - log(1/0.99-1) / k_1 = w_1 - log(1/99) / k_1
\end{align*}

as the function has had $99\%$ of the increase of the sigmoid curve up to this point.

Setting the boundaries in line 2 is non-trivial. We have noted that a condition such as $0 \leq u \leq d \leq a$, $w_1 \leq t \leq w_2$, $k_1 > 0$ and $k_2 < 0$ are expected. We want to impose them using boundaries in which the parameters must lie. However, boundaries for each parameter must not depend on other parameters. We can circumvent this by changing the parameters to be relative to each other. As $u \leq d \leq a$ we choose to use the three parameters $u, d-u$ and $a-d$. We can then set the lower boundary to be $0$ which ensures

\begin{align*}
	0 \leq u &&\land &&0 \leq d - u \implies d \geq u &&\land &&0 \leq a - d \implies a \geq d\\
	&& &&\implies 0 \leq u \leq d \leq a.
\end{align*}

Using the same method, we choose the parameters $w_1 - start$ and $w_2 - w_1$, where $start$ is the first frame in which the particle was tracked. The resulting boundaries are described in table~\ref{tab:boundaries_and_starting_vals}, where we set min val, max val and median val as the minimum, maximum and median of the particles' ratio data respectively while start and end is the first and last frame where data was recorded for this particle.

The condition $t \leq w_2$ can be violated, but it is ensured that at least $w_1 \leq w_2$.

The other conditions are met as $k_1 \in [0.05, 10] \implies k_1 > 0$ while $k_2 \in [-1, -0.01] \implies k_2 < 0$ and

\begin{align*}
	t = w_1 - \underbrace{log(1/99) / k_1}_{< 0} \geq w_1.
\end{align*}

\begin{table}[h!]
	\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		\textbf{parameter} & \textbf{lower bound} & \textbf{upper bound} & \textbf{starting value} \\ 
		\hline
		$u$ & min val & max val & min val\\
		\hline
		$d - u$ & 0 & max val & median val - min val\\
		\hline
		$a - d$ & 0 & max val & max val - median val\\
		\hline
		$w_1 - start$ & 0 & end - start & 0\\
		\hline
		$w_2 - w_1$ & 0 & end - start & (end - start) / 2\\
		\hline
		$k_1$ & 0.05 & 10 & 0.1\\
		\hline
		$k_2$ & -1 & -0.01 & -0.03\\
		\hline
		\hline
		$d$ & min val & 2 max val & median val \\
		\hline
		$a$ & min val & 3 max val & max val \\
		\hline
		$w_1$ & start & end & start \\
		\hline
		$w_2$ & start & 2 end - 2 start & (start + end)/2\\
		\hline
	\end{tabular}
	\caption{Upper and lower bounds as well as starting value for each of the parameters. The boundaries and starting values of $d, a, w_1$ and $w_2$ are derived from the parameters used in the implementation of the approximation, shown above the double line.}
	\label{tab:boundaries_and_starting_vals}
\end{table}

Starting values can have a big impact on the approximation reached by the algorithm. We want to choose starting values close to the expected resulting parameters. By choosing the starting value of $w_1 - start$ as $0$, which corresponds to choosing $w_1 = start$, we favour the first increase in the data to be the point of activation. Otherwise, we are more likely to mistake an oscillation later in the data as the activation point. As we do not know when the activation happens when setting the boundaries we guess that $w_2$ will lie somewhere in the middle. Therefore we choose $(end - start)/2$ as the starting value for $w_2 - w_1$. The other starting values are chosen as we expect $u$ to be low, $a$ to be high, $d$ to lie somewhere in the middle. Experimenting showed that $k_1$ often has a value around $0.1$ while $k_2$ lies around $-0.03$.

Using algorithm~\ref{alg:approximate} we now describe a routine which handles reading the data, some necessary preprocessing steps and saving of the resulting parameter lists.

\begin{algorithm}[H] \label{alg:main}
	\SetAlgoLined
	\DontPrintSemicolon
	\LinesNumbered
	\SetKwInOut{Input}{input}
	\SetKwInOut{Output}{output}
	\caption{Approximation Loop}
	
	\Input{file containing data matrix as described in section \ref{sec:structure_of_data}}
	\Output{parameters of the approximation of all particles as a matrix}
	
	\BlankLine
	\Begin{
		read data\;
		filter data\;
		\For{each single particle}{
			particle data := (frame, ratio) columns of this particle\;
			\If{length of particle data is too short}{
				skip\;
			}
			parameters := approximate(particle data)\;
			optionally show ratio data and approximation\;
			save parameters\;
		}
		\Return{matrix of all parameters}
	}
\end{algorithm}
\vspace{1cm}

Filtering the data is necessary as the ratio can be very large if the denominator is small. Values are therefore bounded to lie within the interval $[0, 5]$. Any values higher than 5 are almost certainly caused by measurement errors. Values below 0 are definitely incorrect, as both the denominator and enumerator are measured as the brightness of a pixel, which can not be negative.

The visualization in line 10 of algorithm~\ref{alg:main} generates images such as figure~\ref{fig:particle_vis_sigmoid_approx}.

\begin{figure}[h]
	\centering
	\begin{subfigure}{0.45\linewidth}
		\includegraphics[width=\textwidth]{fig/particle_vis_sigmoid_approx_pos}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\linewidth}
		\includegraphics[width=\textwidth]{fig/particle_vis_sigmoid_approx_neg}
	\end{subfigure}
	
	\caption{The left plot shows the data in black and approximation in orange of an activated cell. The first plot is scaled from 0 to 5, the second one is scaled to fit the data. The right plot shows the same of an unactivated cell.}
	\label{fig:particle_vis_sigmoid_approx}
\end{figure}


This work uses the python scipy function \texttt{scipy.optimize.curve\_fit(function, xdata, ydata, p0=starting\_values, method='trf', bounds=(lower\_bounds, upper\_bounds))} as it provides all the necessary functionality. The method parameter \texttt{trf} stands for Trust Region Reflective, as described in section~\ref{subsec:algorithms_bounded_lsp}.

\newpage
\section{Analysis of the Approximation}
\label{sec:analysis_of_approximation}

We now give data on the parameters found from the above approximation. Some statistics are found in table~\ref{tab:statistics_parameters}. Figure~\ref{fig:parameter_violin_plot} shows the distribution of the resulting parameters of the approximation. From the figure it seems the differences between activated and unactivated cells is biggest in the parameters activated value $a$, decreased value $d$ as well as the steepness of increase $k_1$.

\begin{table}[h!]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|c|}
		\hline
		 & & \multicolumn{2}{|c|}{Positive Control} & \multicolumn{2}{|c|}{Negative Control} & \\ 
		\hline
		& Parameter & Average & Standard Deviation & Average & Standard Deviation & Difference \\ 
		\hline
		\multirow{7}{*}{\rotatebox[origin=c]{90}{human cells}} & $a$ & 2.808 & 0.461 & 0.923 & 0.669 & 1.885\\
		\cline{2-7}
		& $u$ & 0.663 & 0.521 & 0.613 & 0.311 & 0.05\\
		\cline{2-7}
		& $d$ & 1.937 & 0.491 & 0.685 & 0.412 & 1.252\\
		\cline{2-7}
		& $k_1$ & 0.263 & 0.428 & 0.524 & 0.963 & -0.261 \\
		\cline{2-7}
		& $k_2$ & -0.059 & 0.164 & -0.163 & 0.292 & 0.104 \\
		\cline{2-7}
		& $w_1$ & 142.228 & 124.012 & 171.062 & 131.563 & -28.834 \\
		\cline{2-7}
		& $w_2$ & 445.386 & 185.971 & 478.843 & 190.792 & -33.457 \\
		\hline
		\multirow{7}{*}{\rotatebox[origin=c]{90}{mouse cells}} & $a$ & 2.9 & 0.907 & 0.876 & 0.186 & 2.024 \\
		\cline{2-7}
		& $u$ & 0.889 & 0.27 & 0.79 & 0.093 & 0.099 \\
		\cline{2-7}
		& $d$ & 1.749 & 0.407 & 0.804 & 0.129 & 0.945 \\
		\cline{2-7}
		& $k_1$ & 0.15 & 0.409 & 1.161 & 1.235 & -1.011 \\
		\cline{2-7}
		& $k_2$ & -0.1 & 0.195 & -0.133 & 0.267 & 0.033 \\
		\cline{2-7}
		& $w_1$ & 295.809 & 77.207 & 100.712 & 112.352 & 195.097 \\
		\cline{2-7}
		& $w_2$ & 469.952 & 105.375 & 304.283 & 179.834 & 165.669 \\
		\hline
	\end{tabular}
	\caption{Statistics of the parameters retrieved from approximating the human cell data.}
	\label{tab:statistics_parameters}
\end{table}

\begin{figure}[h]
	\centering
	\begin{subfigure}{0.45\linewidth}
		\includegraphics[width=\textwidth]{fig/parameter_violin_plot_human_pos}
	\end{subfigure}
	\hfill
	\begin{subfigure}{0.45\linewidth}
		\includegraphics[width=\textwidth]{fig/parameter_violin_plot_human_neg}
	\end{subfigure}
	
	\caption{Violin plots of parameters $u, a, d, w_1, w_2, k_1$ and $k_2$ from the approximations. The parameters of the positive control are on the left and those of the negative control are on the right. Both are of human cells.}
	\label{fig:parameter_violin_plot}
\end{figure}

As the datasets are not perfectly labelled, meaning there are activated cells in the negative control and vice versa, we have relatively high standard deviation.

We can use the mean and standard deviation of each of the parameters to find data points that can be considered outliers. We expect wrongly-labelled data, e.g. activated cells in the negative control, to be an outlier in the parameters $a$ and $d$. However, activated cells in the positive control might have a decreased value $d$ that is very low, around $u$. This makes it difficult to distinguish activated from unactivated cells when looking at the parameter $d$. Therefore, we choose $a$ as the only parameter when filtering for these kinds of outliers.

A particle from the positive control dataset that has a value in parameter $a$ higher than the median should still be classified as activated. Only a value lower than some threshold indicates an unactivated cell. The same holds for values of $a$ lower than the median in the negative control dataset. In short, we want to filter out particles with a high value of $a$ in the negative control and those with a low value of $a$ in the positive control dataset. Therefore, the threshold has to be specified as a lower and upper bound in multiples of the standard deviation.

We give pseudocode for the detection of outliers.

\begin{algorithm}[H] \label{alg:outlier_detection}
	\SetAlgoLined
	\DontPrintSemicolon
	\LinesNumbered
	\SetKwInOut{Input}{input}
	\SetKwInOut{Output}{output}
	\caption{Find Outliers}
	
	\Input{data as matrix of all particle parameters of the approximation, threshold as pair, parameters\_used as list}
	\Output{set of indices of the outliers}
	
	\BlankLine
	\Begin{
		outliers := empty set\;
		\For{parameter in parameteres\_used}{
			mean := mean(data[parameter])\;
			std := standard\_deviation(data[parameter])\;
			interval := [mean - std $\cdot$ threshold[0], mean - std $\cdot$ threshold[1]]\;
			outliers = outlier $\cup$ \{data[index] : data[parameter] $\not\in$ interval\}\;
		}
		\Return{outliers}
	}
\end{algorithm}
\vspace{1cm}

The question of how to choose the threshold will be discussed next. As we do not have information on what percentage of cells behaved correctly in the positive and negative control we do not have enough information to choose threshold values without guessing. Instead, we can manipulate the threshold as a multiple of the standard deviation until we filter out incorrectly labelled data, but would filter out correctly labelled data points if we increase the value. This trial and error approach led to different values for each of the four control datasets, which can be seen in table~\ref{tab:threshold_outlier}.

\begin{table}[h!]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		dataset & lower bound & upper bound \\
		\hline
		human positive & mean $ - 3$ std $ = 1.582$ & $\infty$ \\
		\hline
		human negative & $-\infty$ & mean $ + 0.5$ std $ = 1.306$ \\
		\hline
		mouse positive & mean $ - 2$ std $ = 1.41$ & $\infty$ \\
		\hline
		mouse negative & $-\infty$ & mean $ + 3$ std $ = 1.445$ \\
		\hline
	\end{tabular}
	\caption{Thresholds in outlier detection in the different datasets.}
	\label{tab:threshold_outlier}
\end{table}

Naturally we can use the same outlier detection with different parameters to find particles where the approximation failed to yield a good result.

These results will be used in section~\ref{sec:proposed-algorithm} to remove wrongly-labelled data from the datasets.

\section{Adding Oscillation to the Approximation}
\label{sec:adding_oscillation_to_the_approximation}

In order to answer the questions from chapter~\ref{chapter:introduction} concerned with the oscillations  happening in the decrease of the \Calcium concentration we want to model them as well. We use a method often used when analysing oscillating data, called Fourier Transformation.

Fourier Transformation is used when an application is concerned with cyclic temporal data. Examples are sound waves, seismic data or oscillations of a skyscraper in strong wind. This data can be represented as a function of amplitude over time. Most of the time we are not interested in the amplitude at a specific point in time, as a temporal shift would represent very similar information. Such a shift is demonstrated in figure~\ref{fig:tempoal_shift}.

\begin{figure}[h]
	\centering
	
	\begin{subfigure}[b]{\textwidth}
		\begin{tikzpicture}
			\begin{axis}[xlabel=Time, ylabel=Amplitude, width=\textwidth, height=0.4\textwidth]
				\addplot+ [domain=0:pi, samples=100, no marks, color=black, style=solid]{0};
				\addplot+ [domain=pi:3*pi, samples=100, no marks, color=black, style=solid]{sin(deg(x)) + 0.5*sin(deg(4*x)) + 0.1*sin(deg(10*x))};
				\addplot+ [domain=3*pi:15, samples=100, no marks, color=black, style=solid]{0};
				
				\addplot+ [domain=0:pi+2, samples=100, no marks, color=red, style=solid]{0};
				\addplot+ [domain=pi+2:3*pi+2, samples=100, no marks, color=red, style=solid]{sin(deg(x-2)) + 0.5*sin(deg(4*(x-2))) + 0.1*sin(deg(10*(x-2)))};section
				\addplot+ [domain=3*pi+2:15, samples=100, no marks, color=red, style=solid]{0};
			\end{axis}
		\end{tikzpicture}
	\end{subfigure}
	
	\caption{Two signals that differ by a temporal shift.}
	\label{fig:tempoal_shift}
\end{figure}

As the function of sound waves or oscillations in the \Calcium concentration in t cells is almost cyclic we might be interested in a decomposition into simple cyclic function, such as sine. We can then analyse the most prominent frequencies and their respective amplitudes. This gives a representation of the data, that can be easier to interpret. Fast Fourier Transformation (FFT) is an algorithm that transforms temporal data into such a representation of a weighted sum of sines.

As the oscillations happen in the decrease of the \Calcium concentration we apply FFT to that part of the data. We can use the frequency with the highest amplitude and use them to further analyse the oscillations. After having found this estimation of the frequency we can use the method from before, but with a sin function instead of the sigmoid functions. In detail, we once again utilize \texttt{scipy.optimize.curve\_fit}, this time using the function

\begin{align*}
	f(x, A, w, p) := A \cdot \sin(w \cdot t + p)
\end{align*}

with parameters amplitude $A$, angular frequency $w$ and phase $p$. The starting value for the approximation can be set using the results of the FFT. We denote the frequency with the highest amplitude returned from the FFT by $f_{guess}$ and the standard deviation of the approximation residuum time series with $std(Y)$. Then we can set the start value of $A$ to be $\sqrt{2 \cdot std(Y)}$, the one of $w$ to be $2\pi |f_{guess}|$ and the one of $p$ to be $0$.

The drawback of this method is that only oscillations that can be represented by a single sin function can be modelled. However, for our purpose we can assume that the oscillations are of this form.

Doing this gives an even better approximation of the data, which can be seen in figure~\ref{fig:particle_vis_fft_approx}.

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth]{fig/particle_vis_fft_approx_pos}
	
	\caption{The data of an activated cell with heavy oscillation is shown in black, simple approximation in orange and the approximation with FFT added in red. The first plot is scaled from 0 to 5, the second one is scaled to fit the data.}
	\label{fig:particle_vis_fft_approx}
\end{figure}

We store the data gathered from the approximation as a list of frequency, amplitude and phase.
